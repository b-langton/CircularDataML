{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import randint\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from scipy.stats import vonmises\n",
    "import numpy.fft as fft \n",
    "import math\n",
    "res = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the network to train on the data \n",
    "class CircleNet(nn.Sequential): \n",
    "    def __init__(self, res, dropout, n_out): \n",
    "        super(CircleNet, self).__init__()\n",
    "        self.n_in = res\n",
    "        self.affine1 = nn.Linear(self.n_in, 6)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        ##self.affine2 = nn.Linear(8, 4)\n",
    "        ##self.drop2 = nn.Dropout(dropout)\n",
    "        self.affine3 = nn.Linear(6, n_out)\n",
    "    def forward(self, x): \n",
    "        x = F.relu(self.affine1(x))\n",
    "        x = self.drop1(x)\n",
    "        ##x = F.relu(self.affine2(x))\n",
    "        ##x = self.drop2(x)\n",
    "        x = F.relu(self.affine3(x))\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Data Generation Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make some uniform circular data\n",
    "std = 2.76\n",
    "mean = 8.5\n",
    "res = 12\n",
    "num_points = 100\n",
    "num_samples = 100\n",
    "data = np.zeros([num_points,res + 1])\n",
    "for i in range(num_points): \n",
    "    for j in range(num_samples): \n",
    "        num = randint(0,res-1)\n",
    "        data[i][num]+= 1\n",
    "        data[i][res] = -1\n",
    "    data[i][:-1] = (data[i][:-1]-mean)/std\n",
    "np.savetxt(\"uniform12ptdata100test.csv\", data, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make Data for variable number of samples\n",
    "num_points = 2500\n",
    "res = 12\n",
    "data = np.zeros([num_points, res+1])\n",
    "\n",
    "std_factor = math.sqrt(1/res*(1-1/res))\n",
    "for i in range(num_points):\n",
    "    num_samples = randint(10,110)\n",
    "    mean = num_samples/res\n",
    "    for j in range(num_samples): \n",
    "        num = randint(0,res - 1)\n",
    "        data[i][num] += 1\n",
    "    data[i][res] = -1\n",
    "    data[i][:-1] = (data[i][:-1] - mean)/std_factor/math.sqrt(num_samples)\n",
    "np.savetxt(\"uniformvariablenumtest.csv\", data, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Make Von Mises for variable number of samples\n",
    "num_points = 2500\n",
    "data = np.zeros([num_points,res+1])\n",
    "std_factor = math.sqrt(1/res*(1-1/res))\n",
    "\n",
    "for i in range(num_points):\n",
    "    SAMPLE_SIZE = randint(10,110)\n",
    "    kappa = 1\n",
    "    rotate_amt = random.random()*2*np.pi\n",
    "    rotate_amt2 = random.random()*2*np.pi\n",
    "    mean = SAMPLE_SIZE/res\n",
    "    vm_dist = vonmises.rvs(kappa, loc = rotate_amt, size=SAMPLE_SIZE)\n",
    "  \n",
    "    for l in range(SAMPLE_SIZE):\n",
    "        vm_dist[l] = ((vm_dist[l] + np.pi)/(2*np.pi))%1*(res*10)//10\n",
    "        \n",
    "        data[i][int(vm_dist[l])] += 1\n",
    "       \n",
    "    ##rotate_amt = randint(0,res - 1)\n",
    "    ##data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i][:-1] = (data[i][:-1] - mean)/std_factor/math.sqrt(SAMPLE_SIZE)\n",
    "    data[i,-1] = -7\n",
    "\n",
    "np.savetxt(\"vonmises12variabletest.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(data[10][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([10000,res+1])\n",
    "for i in range(10000):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1\n",
    "    rotate_amt = random.random()*2*np.pi\n",
    "    vm_dist = vonmises.rvs(kappa, loc = rotate_amt, size=SAMPLE_SIZE)\n",
    "    for l in range(SAMPLE_SIZE):\n",
    "        random_rotate_factor = randint(0,1)\n",
    "        vm_dist[l] = ((vm_dist[l] + np.pi + np.pi*random_rotate_factor)/(2*np.pi))%1*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    ##rotate_amt = randint(0,res - 1)\n",
    "    ##data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i][:-1] = (data[i][:-1] - 12)/5\n",
    "    data[i,-1] = -6\n",
    "np.savetxt(\"bimodal8pt100.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([10000,res+1])\n",
    "std = 3.7\n",
    "mean = 8.5\n",
    "for i in range(10000):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1.5\n",
    "    rotate_amt = random.random()*2*np.pi\n",
    "    rotate_amt2 = random.random()*2*np.pi\n",
    "    vm_dist = vonmises.rvs(kappa, loc = rotate_amt, size=SAMPLE_SIZE//2)\n",
    "    vm_dist2 = vonmises.rvs(kappa, loc = rotate_amt2, size = SAMPLE_SIZE//2)\n",
    "    for l in range(SAMPLE_SIZE//2):\n",
    "        vm_dist[l] = ((vm_dist[l] + np.pi)/(2*np.pi))%1*(res*10)//10\n",
    "        vm_dist2[l] = ((vm_dist2[l] + np.pi)/(2*np.pi))%1*(res*10)//10\n",
    "        data[i][int(vm_dist[l])] += 1\n",
    "        data[i][int(vm_dist2[l])]+=1\n",
    "    ##rotate_amt = randint(0,res - 1)\n",
    "    ##data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i][:-1] = (data[i][:-1] - mean)/std\n",
    "    data[i,-1] = -7\n",
    "np.savetxt(\"vonmises12pt100.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1.5\n",
    "    rotate_amt = random.random()*2*np.pi\n",
    "    vm_dist = vonmises.rvs(kappa, loc = rotate_amt, size=SAMPLE_SIZE)\n",
    "   \n",
    "      \n",
    "    vm_dist = ((vm_dist + np.pi)/(2*np.pi))%1*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    ##rotate_amt = randint(0,res - 1)\n",
    "    ##data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i][:-1] = (data[i][:-1] - 12)/5\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptnormalizedtest.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is a class that allows us to load data from csv files and make them into datasets that the dataloader can use\n",
    "class CircularDataset(Dataset): \n",
    "    def __init__(self, data_root): \n",
    "        self.data = []\n",
    "        self.dist_coder = LabelEncoder()\n",
    "        self.dist_list = []\n",
    "        for path in data_root: \n",
    "            array = pd.read_csv(path)\n",
    "            \n",
    "            self.dist_list += [array.values[0,-1]] ##get the distribution type for each file and add it to the list\n",
    "            if len(self.data) == 0: \n",
    "                self.data = array.values\n",
    "            else:\n",
    "                print(self.data.shape)\n",
    "                print(array.values.shape)\n",
    "                self.data = np.concatenate((self.data,array.values), axis = 0)\n",
    "        self.dist_coder.fit(self.dist_list)\n",
    "    def __getitem__(self,idx): \n",
    "        return self.data[idx][0:-1], self.to_one_hot(self.dist_coder,([self.data[idx,-1]]))[0]\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    def to_one_hot(self, codec, values):\n",
    "        value_idxs = codec.transform(values)\n",
    "        return torch.eye(len(codec.classes_))[value_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code where we train the network on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.05)\n",
    "rate = .005\n",
    "batchsize = 100\n",
    "dataset = CircularDataset([\"uniformvariablenum.csv\",\"vonmises12variable.csv\"])\n",
    "testdata = CircularDataset([\"uniformvariablenumtest.csv\", \"vonmises12variabletest.csv\"])\n",
    "\n",
    "iterator = torch.utils.data.DataLoader(dataset, batch_size = batchsize, shuffle = True)\n",
    "testiterator = torch.utils.data.DataLoader(testdata, batch_size = 1, shuffle = True)\n",
    "net = CircleNet(12,0,2)\n",
    "optimizer = optim.Adam(net.parameters(),lr = rate)\n",
    "running_loss = 0\n",
    "netlist = []\n",
    "epochs = 12\n",
    "net.apply(init_weights)\n",
    "net.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for e in range(epochs): \n",
    "    print(running_loss)\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "    i = 0\n",
    "    for dist, labels in iterator: \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = net(dist.float())\n",
    "        \n",
    "        loss = loss_func(out,torch.max(labels, 1)[1])\n",
    "       \n",
    "           \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "    for dist, labels in testiterator: \n",
    "        ps = net(dist.float())\n",
    "\n",
    "        i += 1\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "       \n",
    "        top_p2, top_class2 = labels.topk(1, dim = 1)\n",
    "        \n",
    "        equals = top_class == top_class2\n",
    "        \n",
    "        accuracy += torch.sum(equals.float())\n",
    "        \n",
    "    \n",
    "    print(accuracy)\n",
    "    print(i)\n",
    "    accuracy = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CircularDataset([\"uniformvariablenum.csv\", \"vonmises12variable.csv\"])\n",
    "def sum(x):\n",
    "    tot = 0\n",
    "    for i in x: \n",
    "        tot += i\n",
    "    return tot\n",
    "\n",
    "for i in range(100):\n",
    "    print(sum(np.abs(dataset.__getitem__(i+25000)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = CircularDataset([\"uniform12ptdata100.csv\"])\n",
    "testiterator = torch.utils.data.DataLoader(testdata, batch_size = 1, shuffle = True)\n",
    "accuracy = 0\n",
    "\n",
    "i = 0\n",
    "for dist, labels in testiterator: \n",
    "    ps = net(dist.float())\n",
    "        \n",
    "    print(dist)\n",
    "    i+=1\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    \n",
    "    top_p2, top_class2 = labels.topk(1, dim = 1)\n",
    "        \n",
    "    equals = top_class == top_class2\n",
    "   \n",
    "    accuracy += torch.sum(equals.float())\n",
    "        \n",
    "print(accuracy/99)\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(vec, num_rotations): \n",
    "    vec2 = np.zeros(len(vec))\n",
    "    for i in range(len(vec)): \n",
    "        vec2[(i + num_rotations )% len(vec)] = vec[i]\n",
    "    return vec2\n",
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1\n",
    "    vm_dist = vonmises.rvs(kappa, size=SAMPLE_SIZE)\n",
    "    vm_dist = (vm_dist + np.pi)/(2*np.pi)*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    \n",
    "    rotate_amt = randint(0,res - 1)\n",
    "    data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptdata100test.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist2 = []\n",
    "for parameter in net.parameters(): \n",
    "    paramlist2 += [parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savednet2 = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2 = paramlist2[0].detach().numpy()\n",
    "array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.around(np.matmul(array2,fft.ifft(np.identity(12),12)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft.irfft(np.identity(8),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(torch.from_numpy(dataset.__getitem__(1)[0]).float()/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(savednet2.state_dict(), \"8x6x2bianduniexample.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dataset:\n",
    "    print(sum(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "mean = [0, 0]\n",
    "cov = [[2/3, 0], [0, 2/3]]\n",
    "x, y = np.random.multivariate_normal(mean, cov, 5000).T\n",
    "x, y = abs(x), abs(y)\n",
    "\n",
    "# Gen the data\n",
    "a = np.random.multivariate_normal(mean, cov, 5000)\n",
    "plt.plot([x[0] for x in a], [x[1] for x in a], 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "a = [np.absolute(x) for x in a]\n",
    "plt.plot([x[0] for x in a], [x[1] for x in a], 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "a = np.asarray(a)\n",
    "# project each value onto its maximum axis\n",
    "row_maxes = a.max(axis=1).reshape(-1, 1)\n",
    "a = np.where(a == row_maxes, row_maxes, 0)\n",
    "\n",
    "plt.plot([x[0] for x in a], [x[1] for x in a], 'x')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "    \n",
    "def multidimsample(n, samples=1000):\n",
    "    mean = [0 for i in range(n)]\n",
    "    cov = [[0 if row == col else 1 for col in range(n)] for row in range(n)]\n",
    "    res = np.random.multivariate_normal(mean, cov, samples)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
