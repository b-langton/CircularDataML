{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import randint\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from scipy.stats import vonmises\n",
    "import numpy.fft as fft \n",
    "res = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the network to train on the data \n",
    "class CircleNet(nn.Sequential): \n",
    "    def __init__(self, res, dropout, n_out): \n",
    "        super(CircleNet, self).__init__()\n",
    "        self.n_in = res\n",
    "        self.affine1 = nn.Linear(self.n_in, 6)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        ##self.affine2 = nn.Linear(8, 4)\n",
    "        ##self.drop2 = nn.Dropout(dropout)\n",
    "        self.affine3 = nn.Linear(6, n_out)\n",
    "    def forward(self, x): \n",
    "        x = F.relu(self.affine1(x))\n",
    "        x = self.drop1(x)\n",
    "        ##x = F.relu(self.affine2(x))\n",
    "        ##x = self.drop2(x)\n",
    "        x = F.relu(self.affine3(x))\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Data Generation Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make some uniform circular data\n",
    "res = 8\n",
    "num_points = 10000\n",
    "num_samples = 100\n",
    "data = np.zeros([num_points,res + 1])\n",
    "for i in range(num_points): \n",
    "    for j in range(num_samples): \n",
    "        num = randint(0,res-1)\n",
    "        data[i][num]+= 1\n",
    "        data[i][res] = -1\n",
    "    data[i][:-1] = (data[i][:-1]-12)/5\n",
    "np.savetxt(\"uniform8ptdata100.csv\", data, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([10000,res+1])\n",
    "for i in range(10000):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1.5\n",
    "    rotate_amt = random.random()*2*np.pi\n",
    "    vm_dist = vonmises.rvs(kappa, loc = rotate_amt, size=SAMPLE_SIZE)\n",
    "    for l in range(SAMPLE_SIZE):\n",
    "        random_rotate_factor = randint(0,1)\n",
    "        vm_dist[l] = ((vm_dist[l] + np.pi + np.pi*random_rotate_factor)/(2*np.pi))%1*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    ##rotate_amt = randint(0,res - 1)\n",
    "    ##data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i][:-1] = (data[i][:-1] - 12)/5\n",
    "    data[i,-1] = -6\n",
    "np.savetxt(\"bimodal8pt100.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1.5\n",
    "    rotate_amt = random.random()*2*np.pi\n",
    "    vm_dist = vonmises.rvs(kappa, loc = rotate_amt, size=SAMPLE_SIZE)\n",
    "   \n",
    "      \n",
    "    vm_dist = ((vm_dist + np.pi)/(2*np.pi))%1*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    ##rotate_amt = randint(0,res - 1)\n",
    "    ##data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i][:-1] = (data[i][:-1] - 12)/5\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptnormalizedtest.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 14.  4. 18. 15. 11.  9. 14. -6.]\n"
     ]
    }
   ],
   "source": [
    "print(data[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is a class that allows us to load data from csv files and make them into datasets that the dataloader can use\n",
    "class CircularDataset(Dataset): \n",
    "    def __init__(self, data_root): \n",
    "        self.data = []\n",
    "        self.dist_coder = LabelEncoder()\n",
    "        self.dist_list = []\n",
    "        for path in data_root: \n",
    "            array = pd.read_csv(path)\n",
    "            \n",
    "            self.dist_list += [array.values[0,-1]] ##get the distribution type for each file and add it to the list\n",
    "            if len(self.data) == 0: \n",
    "                self.data = array.values\n",
    "            else:\n",
    "                print(self.data.shape)\n",
    "                print(array.values.shape)\n",
    "                self.data = np.concatenate((self.data,array.values), axis = 0)\n",
    "        self.dist_coder.fit(self.dist_list)\n",
    "    def __getitem__(self,idx): \n",
    "        return self.data[idx][0:-1], self.to_one_hot(self.dist_coder,([self.data[idx,-1]]))[0]\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    def to_one_hot(self, codec, values):\n",
    "        value_idxs = codec.transform(values)\n",
    "        return torch.eye(len(codec.classes_))[value_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code where we train the network on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 9)\n",
      "(9999, 9)\n",
      "(19998, 9)\n",
      "(9999, 9)\n",
      "(99, 9)\n",
      "(99, 9)\n",
      "(198, 9)\n",
      "(99, 9)\n",
      "0\n",
      "tensor(215.)\n",
      "297\n",
      "tensor(296.0301, grad_fn=<AddBackward0>)\n",
      "tensor(245.)\n",
      "297\n",
      "tensor(243.9988, grad_fn=<AddBackward0>)\n",
      "tensor(245.)\n",
      "297\n",
      "tensor(233.5331, grad_fn=<AddBackward0>)\n",
      "tensor(249.)\n",
      "297\n",
      "tensor(229.1032, grad_fn=<AddBackward0>)\n",
      "tensor(261.)\n",
      "297\n",
      "tensor(211.3859, grad_fn=<AddBackward0>)\n",
      "tensor(264.)\n",
      "297\n",
      "tensor(207.6109, grad_fn=<AddBackward0>)\n",
      "tensor(263.)\n",
      "297\n",
      "tensor(206.1604, grad_fn=<AddBackward0>)\n",
      "tensor(264.)\n",
      "297\n",
      "tensor(205.1253, grad_fn=<AddBackward0>)\n",
      "tensor(262.)\n",
      "297\n",
      "tensor(204.4244, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-3137f3c626f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e6dc5d258ac1>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist_coder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_one_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist_coder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e6dc5d258ac1>\u001b[0m in \u001b[0;36mto_one_hot\u001b[1;34m(self, codec, values)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_one_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mvalue_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcodec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_idxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.05)\n",
    "rate = .005\n",
    "batchsize = 100\n",
    "dataset = CircularDataset([\"uniform8ptdata100.csv\", \"bimodal8pt100.csv\",\"vonmises8ptnormalized.csv\"])\n",
    "testdata = CircularDataset([\"uniform8ptdata100test.csv\", \"bimodal8pt100test.csv\",\"vonmises8ptnormalizedtest.csv\"])\n",
    "iterator = torch.utils.data.DataLoader(dataset, batch_size = batchsize, shuffle = True)\n",
    "testiterator = torch.utils.data.DataLoader(testdata, batch_size = 1, shuffle = True)\n",
    "net = CircleNet(8,0,3)\n",
    "optimizer = optim.Adam(net.parameters(),lr = rate)\n",
    "running_loss = 0\n",
    "epochs = 10\n",
    "net.apply(init_weights)\n",
    "net.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for e in range(epochs): \n",
    "    print(running_loss)\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "    i = 0\n",
    "    for dist, labels in iterator: \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = net(dist.float())\n",
    "        \n",
    "        loss = loss_func(out,torch.max(labels, 1)[1])\n",
    "       \n",
    "           \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "    for dist, labels in testiterator: \n",
    "        ps = net(dist.float())\n",
    "        \n",
    "        i += 1\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "       \n",
    "        top_p2, top_class2 = labels.topk(1, dim = 1)\n",
    "        \n",
    "        equals = top_class == top_class2\n",
    "       \n",
    "        accuracy += torch.sum(equals.float())\n",
    "        \n",
    "    \n",
    "    print(accuracy)\n",
    "    print(i)\n",
    "    accuracy = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  1.0000,  1.0000, -1.0000,  1.0000,  0.0000,  0.0000, -1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.6000,  0.0000,  1.6000, -0.2000, -1.0000,  1.0000,  0.4000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.4000,  1.4000, -0.2000, -0.4000, -0.6000,  0.8000, -0.8000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000, -0.2000, -0.2000,  0.0000, -0.2000,  0.6000,  1.2000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.6000, -0.8000, -0.8000, -0.4000,  1.6000, -0.8000, -0.2000,  0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.4000, -0.6000, -0.6000, -0.2000,  0.0000, -0.4000,  1.2000,  1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.2000,  0.0000,  0.6000,  0.4000,  0.0000,  1.2000, -0.6000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.0000,  0.4000, -0.4000,  0.0000,  1.0000,  0.2000, -0.6000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.4000,  0.6000,  1.0000,  0.8000, -1.0000,  0.8000, -0.2000, -1.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.4000,  1.4000,  1.0000, -0.2000,  0.0000,  1.0000,  0.4000, -1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.6000, -1.0000,  0.2000, -0.6000, -0.8000,  2.0000,  1.6000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000,  1.4000,  0.6000,  0.0000,  0.8000, -1.4000, -0.6000,  0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.2000,  1.2000,  0.2000, -0.8000,  0.4000,  0.6000, -0.2000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  0.0000,  1.2000,  0.0000, -0.8000, -0.8000,  0.0000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.6000, -1.2000,  0.8000,  0.2000,  0.2000, -0.4000, -0.8000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.6000,  1.8000, -1.2000, -0.6000,  0.6000,  0.2000,  0.8000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000,  1.2000, -1.6000,  0.2000,  1.2000,  0.4000, -1.0000,  0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.6000,  0.6000,  1.0000,  0.0000, -1.2000,  1.8000,  0.0000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 2.8000,  0.2000, -1.2000, -1.8000,  0.0000,  1.8000,  0.0000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.0000,  0.4000,  0.4000,  1.8000, -1.0000, -0.2000,  0.8000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.0000,  0.2000,  0.8000,  0.0000, -0.4000,  0.4000,  0.6000,  0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.6000,  0.2000,  0.8000, -1.0000, -1.6000,  0.2000,  1.6000,  1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000,  1.4000, -0.2000, -1.2000,  1.2000,  0.8000, -0.2000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  0.8000, -1.4000, -0.4000,  0.4000,  2.2000, -0.4000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000,  1.0000,  0.6000, -1.6000,  0.2000,  0.8000,  1.0000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000, -0.8000,  0.0000,  2.2000,  0.6000, -1.4000, -0.6000,  0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.6000, -0.4000, -1.0000,  0.2000,  0.6000, -0.2000, -0.4000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000,  2.6000, -0.2000, -0.4000,  0.0000,  0.4000, -0.8000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000, -0.2000,  1.0000,  0.8000, -0.2000, -0.6000, -0.4000,  0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.8000,  0.4000,  0.0000,  1.0000, -0.6000, -0.8000, -1.0000,  1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.6000,  0.4000,  1.0000, -1.0000, -0.4000, -0.4000,  0.8000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000, -0.8000, -0.2000,  0.6000,  3.0000,  0.4000, -1.0000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.0000,  0.2000,  1.0000,  0.0000, -0.8000,  0.4000,  1.4000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.2000,  0.4000, -0.6000,  0.0000,  0.2000,  1.0000, -0.4000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.8000, -0.2000,  0.0000,  1.4000, -0.2000, -0.8000,  0.6000,  0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  0.4000,  1.2000, -0.8000,  0.6000,  0.8000,  0.2000, -1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.4000,  0.0000, -1.0000,  0.8000,  0.0000, -0.8000, -0.2000,  1.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  1.6000,  0.6000, -1.0000, -0.2000,  0.6000,  1.0000, -1.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  1.0000,  1.0000,  1.0000, -0.8000,  0.2000, -0.4000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000, -1.0000,  0.0000,  2.6000, -1.0000, -0.6000, -0.4000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.0000,  1.4000, -0.4000, -1.6000, -0.4000,  1.8000, -0.4000, -0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.2000, -0.4000, -0.8000,  2.0000, -0.2000, -1.0000, -0.8000,  0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.0000, -0.8000,  1.2000,  1.2000, -2.2000, -0.4000,  0.4000,  0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.2000, -0.8000,  1.2000,  0.6000,  1.2000, -1.2000, -0.6000,  1.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000, -0.4000,  0.4000,  1.0000, -0.6000, -0.8000,  0.2000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.8000, -0.2000,  0.6000, -0.2000, -0.2000, -1.0000,  1.2000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000, -0.2000,  0.8000,  0.6000, -1.6000,  0.2000,  0.6000,  0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.8000,  0.4000,  0.4000, -1.0000,  0.2000,  1.0000,  0.2000, -1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.2000,  0.6000, -1.2000, -1.0000,  0.6000,  1.0000,  1.2000, -0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.2000,  0.0000, -0.8000, -1.0000,  2.2000,  1.0000, -0.4000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.0000,  0.4000,  1.4000, -0.8000, -1.4000,  0.2000,  1.2000,  0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.6000, -0.8000,  1.0000,  1.4000,  0.0000, -0.8000,  0.6000,  1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000, -0.4000,  0.8000, -0.4000, -0.2000,  0.4000,  1.2000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000,  0.0000, -1.0000,  0.2000,  1.0000, -0.6000,  0.8000,  0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.8000,  0.4000, -1.0000, -0.4000,  1.8000,  0.8000, -1.4000, -1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000,  0.6000,  0.0000,  0.0000,  1.8000,  0.4000, -1.4000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.2000, -0.4000,  1.0000,  1.0000,  0.0000, -0.4000, -0.2000,  1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.2000,  0.0000,  1.4000,  0.8000, -1.0000, -0.8000,  0.2000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.0000,  0.0000,  0.0000, -1.0000,  1.2000,  0.4000, -0.4000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000, -0.2000,  0.8000,  0.6000, -0.8000, -0.6000,  1.6000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000, -0.8000,  0.6000,  2.4000, -0.6000, -1.2000, -0.8000,  1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.8000,  1.0000, -0.6000,  0.0000,  0.2000,  2.0000, -1.4000, -1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000, -0.6000, -0.4000,  1.0000, -0.4000, -0.4000,  0.4000,  1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.8000,  1.4000, -1.4000, -1.4000,  0.8000,  2.8000,  1.0000, -1.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.6000, -1.2000, -1.6000,  0.6000,  1.4000, -0.6000, -0.2000,  0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.0000, -0.4000,  1.4000,  0.0000, -1.2000,  0.2000,  0.4000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.2000, -0.4000, -0.8000,  0.4000, -0.4000,  0.6000,  0.0000,  1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.2000, -1.0000, -0.8000,  0.8000,  0.6000,  0.2000, -0.2000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.8000, -0.4000, -0.2000,  0.0000, -1.0000,  0.8000,  2.4000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.0000, -0.4000, -1.6000, -1.2000,  2.2000,  1.4000,  0.0000, -0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.2000,  0.0000, -0.4000, -0.6000,  0.4000,  0.8000,  1.0000, -1.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 2.4000, -1.2000,  1.2000,  1.2000, -0.4000, -0.8000, -1.2000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000, -0.2000,  0.4000, -0.4000,  0.8000,  0.4000,  0.4000, -0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000, -0.8000,  0.4000, -0.2000, -0.4000, -0.2000,  0.0000,  2.4000]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       dtype=torch.float64)\n",
      "tensor([[ 0.4000,  1.6000, -0.6000, -1.2000, -0.2000,  2.2000, -0.6000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.6000, -1.2000,  0.4000,  1.0000,  0.0000, -1.2000, -1.0000,  1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000,  1.6000, -0.2000, -1.2000,  0.2000,  0.8000,  0.0000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000, -0.6000,  1.0000,  0.2000, -0.2000, -0.6000,  0.2000,  1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  1.4000,  0.0000, -0.6000,  0.8000,  1.0000, -0.6000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.6000,  0.0000,  1.2000, -1.4000, -1.0000,  0.6000,  0.8000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.2000,  1.2000,  0.8000, -1.0000, -0.8000,  1.8000,  1.0000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  2.4000, -0.4000, -0.2000, -2.0000,  0.6000,  0.8000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.6000, -0.8000, -0.2000, -0.6000,  0.4000,  0.6000, -1.6000,  1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  0.8000,  1.0000, -1.4000, -0.6000,  1.2000,  1.0000, -1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.8000,  2.6000,  0.2000, -1.4000,  0.2000,  0.6000, -0.8000, -1.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.0000,  0.6000,  0.4000, -1.0000, -0.2000, -0.2000,  1.0000,  0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.2000,  0.8000, -1.2000, -0.6000,  1.8000,  2.0000, -1.0000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.2000,  0.4000, -0.6000,  0.6000,  1.4000, -0.4000,  0.0000, -0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.6000,  1.2000, -0.6000,  0.2000,  0.0000, -0.2000, -0.8000, -0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.6000, -1.0000,  1.0000,  1.6000, -0.2000, -0.8000, -1.2000,  0.8000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-0.4000, -0.6000,  0.2000, -0.4000,  0.2000, -0.4000,  1.0000,  1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-1.0000, -1.2000,  0.2000,  2.4000,  1.0000,  0.0000, -0.8000,  0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.8000,  1.6000, -1.4000, -0.6000, -0.6000,  1.6000, -0.2000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.0000, -0.6000, -1.8000, -0.6000,  2.2000,  1.8000, -1.0000, -0.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.4000, -2.2000,  0.8000,  0.2000,  1.2000, -0.8000, -0.4000,  1.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 0.8000,  0.8000, -0.2000, -0.6000, -0.2000,  2.0000, -0.6000, -1.2000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.8000, -1.6000, -1.6000,  0.4000,  2.2000, -0.6000, -0.4000,  0.6000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 1.4000,  0.8000, -1.4000, -0.2000, -0.4000,  1.0000, -0.8000,  0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 2.4000, -1.0000, -1.0000, -0.4000,  1.8000,  0.2000, -0.8000, -0.4000]],\n",
      "       dtype=torch.float64)\n",
      "tensor(0.)\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "testdata = CircularDataset([\"bimodal8pt100test.csv\"])\n",
    "testiterator = torch.utils.data.DataLoader(testdata, batch_size = 1, shuffle = True)\n",
    "accuracy = 0\n",
    "\n",
    "i = 0\n",
    "for dist, labels in testiterator: \n",
    "    ps = net(dist.float()/20)\n",
    "        \n",
    "    print(dist)\n",
    "    i+=1\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    \n",
    "    top_p2, top_class2 = labels.topk(1, dim = 1)\n",
    "        \n",
    "    equals = top_class == top_class2\n",
    "   \n",
    "    accuracy += torch.sum(equals.float())\n",
    "        \n",
    "print(accuracy/99)\n",
    "print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(vec, num_rotations): \n",
    "    vec2 = np.zeros(len(vec))\n",
    "    for i in range(len(vec)): \n",
    "        vec2[(i + num_rotations )% len(vec)] = vec[i]\n",
    "    return vec2\n",
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1\n",
    "    vm_dist = vonmises.rvs(kappa, size=SAMPLE_SIZE)\n",
    "    vm_dist = (vm_dist + np.pi)/(2*np.pi)*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    \n",
    "    rotate_amt = randint(0,res - 1)\n",
    "    data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptdata100test.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist2 = []\n",
    "for parameter in net.parameters(): \n",
    "    paramlist2 += [parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "savednet2 = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5944755 , -1.6633469 ,  0.5776691 ,  1.0879722 , -0.65692437,\n",
       "        -0.71620417,  1.2153625 ,  0.8287365 ],\n",
       "       [ 0.6978802 , -0.48027298, -2.1328144 , -1.0842304 , -0.2966838 ,\n",
       "         0.24222182,  0.87208647,  1.3551033 ],\n",
       "       [-1.4021107 , -0.6938992 , -0.00644462,  0.8420382 ,  1.0692444 ,\n",
       "         0.8139301 ,  0.4504028 , -0.3948431 ],\n",
       "       [ 1.5802271 , -0.2276735 , -0.8352513 ,  0.8565605 ,  1.6216164 ,\n",
       "        -1.4878672 , -2.996369  , -0.17060782],\n",
       "       [-0.97879785,  0.8147126 , -0.32629663, -1.7353756 ,  0.06200669,\n",
       "         1.6699992 ,  0.02718284, -1.9329549 ],\n",
       "       [ 0.42568463,  0.0226077 , -0.08336811,  0.6659003 ,  1.0164266 ,\n",
       "         0.7175958 ,  0.6100482 ,  0.73010075]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 = paramlist2[0].detach().numpy()\n",
    "array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1+0.j , -0.2-0.1j, -0.5-0.5j, -0. +0.j ,  0. +0.j , -0. -0.j ,\n",
       "        -0.5+0.5j, -0.2+0.1j],\n",
       "       [-0.1+0.j ,  0.3-0.7j,  0.2-0.1j, -0. +0.1j, -0.1+0.j , -0. -0.1j,\n",
       "         0.2+0.1j,  0.3+0.7j],\n",
       "       [ 0.1+0.j , -0.6-0.1j, -0.1-0.j , -0.1+0.j , -0.1+0.j , -0.1-0.j ,\n",
       "        -0.1+0.j , -0.6+0.1j],\n",
       "       [-0.2+0.j ,  0. +0.5j,  0.9-0.3j, -0. -0.1j,  0. +0.j , -0. +0.1j,\n",
       "         0.9+0.3j,  0. -0.5j],\n",
       "       [-0.3+0.j , -0.2-0.1j, -0.1+0.8j, -0. -0.j , -0. +0.j , -0. +0.j ,\n",
       "        -0.1-0.8j, -0.2+0.1j],\n",
       "       [ 0.5+0.j , -0.1-0.2j,  0.1-0.1j, -0. +0.j , -0. +0.j , -0. -0.j ,\n",
       "         0.1+0.1j, -0.1+0.2j]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(np.matmul(array2,fft.ifft(np.identity(8))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.125    ,  0.125    ,  0.125    ,  0.125    ,  0.125    ,\n",
       "         0.125    ,  0.125    ,  0.125    ],\n",
       "       [ 0.25     ,  0.1767767,  0.       , -0.1767767, -0.25     ,\n",
       "        -0.1767767,  0.       ,  0.1767767],\n",
       "       [ 0.25     ,  0.       , -0.25     ,  0.       ,  0.25     ,\n",
       "         0.       , -0.25     ,  0.       ],\n",
       "       [ 0.25     , -0.1767767,  0.       ,  0.1767767, -0.25     ,\n",
       "         0.1767767,  0.       , -0.1767767],\n",
       "       [ 0.125    , -0.125    ,  0.125    , -0.125    ,  0.125    ,\n",
       "        -0.125    ,  0.125    , -0.125    ],\n",
       "       [ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ],\n",
       "       [ 0.       ,  0.       ,  0.       ,  0.       ,  0.       ,\n",
       "         0.       ,  0.       ,  0.       ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft.irfft(np.identity(8),8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.8267,  1.6260,  1.0317,  0.1149, -1.1928, -2.3556, -1.1457,  1.0627],\n",
       "         [-2.6579, -1.6477,  0.0733,  1.0506,  1.7144,  2.1449,  1.0407, -1.2851]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([0.2029, 0.3341], requires_grad=True), Parameter containing:\n",
       " tensor([[ 4.2196,  3.8495],\n",
       "         [-2.9708, -2.5775]], requires_grad=True), Parameter containing:\n",
       " tensor([-6.3560, 11.3028], requires_grad=True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b8f394649ed8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0cfe5bf7a0b6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m##x = self.drop2(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "net(torch.from_numpy(dataset.__getitem__(1)[0]).float()/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(savednet2.state_dict(), \"8x6x2bianduniexample.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
