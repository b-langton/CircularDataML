{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from scipy.stats import vonmises\n",
    "import numpy.fft as fft \n",
    "res = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the network to train on the data \n",
    "class CircleNet(nn.Sequential): \n",
    "    def __init__(self, res, dropout, n_out): \n",
    "        super(CircleNet, self).__init__()\n",
    "        self.n_in = res\n",
    "        self.affine1 = nn.Linear(self.n_in, 2)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        ##self.affine2 = nn.Linear(self.n_in//2, self.n_in//2)\n",
    "        ##self.drop2 = nn.Dropout(dropout)\n",
    "        self.affine3 = nn.Linear(2, n_out)\n",
    "    def forward(self, x): \n",
    "        x = F.relu(self.affine1(x))\n",
    "        x = self.drop1(x)\n",
    "        ##x = F.relu(self.affine2(x))\n",
    "        ##x = self.drop2(x)\n",
    "        x = F.relu(self.affine3(x))\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Data Generation Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make some uniform circular data\n",
    "res = 8\n",
    "num_points = 100\n",
    "num_samples = 100\n",
    "data = np.zeros([num_points,res + 1])\n",
    "for i in range(num_points): \n",
    "    for j in range(num_samples): \n",
    "        num = randint(0,res-1)\n",
    "        data[i][num]+= 1\n",
    "        data[i][res] = -1\n",
    "np.savetxt(\"uniform8ptdata100test.csv\", data, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1\n",
    "    vm_dist = vonmises.rvs(kappa, size=SAMPLE_SIZE)\n",
    "    vm_dist = (vm_dist + np.pi)/(2*np.pi)*(res*10)//10\n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    rotate_amt = randint(0,res - 1)\n",
    "    data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptdata100test.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is a class that allows us to load data from csv files and make them into datasets that the dataloader can use\n",
    "class CircularDataset(Dataset): \n",
    "    def __init__(self, data_root): \n",
    "        self.data = []\n",
    "        self.dist_coder = LabelEncoder()\n",
    "        self.dist_list = []\n",
    "        for path in data_root: \n",
    "            array = pd.read_csv(path)\n",
    "            \n",
    "            self.dist_list += [array.values[0,-1]] ##get the distribution type for each file and add it to the list\n",
    "            if len(self.data) == 0: \n",
    "                self.data = array.values\n",
    "            else:\n",
    "                print(self.data.shape)\n",
    "                print(array.values.shape)\n",
    "                self.data = np.concatenate((self.data,array.values), axis = 0)\n",
    "        self.dist_coder.fit(self.dist_list)\n",
    "    def __getitem__(self,idx): \n",
    "        return self.data[idx][0:-1], self.to_one_hot(self.dist_coder,([self.data[idx,-1]]))[0]\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    def to_one_hot(self, codec, values):\n",
    "        value_idxs = codec.transform(values)\n",
    "        return torch.eye(len(codec.classes_))[value_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code where we train the network on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 9)\n",
      "(9999, 9)\n",
      "(99, 9)\n",
      "(99, 9)\n",
      "0\n",
      "tensor(0.8600)\n",
      "tensor(1125.1398, grad_fn=<AddBackward0>)\n",
      "tensor(0.8850)\n",
      "tensor(972.6840, grad_fn=<AddBackward0>)\n",
      "tensor(0.9000)\n",
      "tensor(953.9169, grad_fn=<AddBackward0>)\n",
      "tensor(0.9100)\n",
      "tensor(947.4997, grad_fn=<AddBackward0>)\n",
      "tensor(0.9150)\n",
      "tensor(944.6589, grad_fn=<AddBackward0>)\n",
      "tensor(0.9150)\n",
      "tensor(942.9575, grad_fn=<AddBackward0>)\n",
      "tensor(0.9250)\n",
      "tensor(941.4842, grad_fn=<AddBackward0>)\n",
      "tensor(0.9150)\n",
      "tensor(940.9153, grad_fn=<AddBackward0>)\n",
      "tensor(0.9200)\n",
      "tensor(940.6455, grad_fn=<AddBackward0>)\n",
      "tensor(0.9000)\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.00)\n",
    "rate = .005\n",
    "batchsize = 10\n",
    "dataset = CircularDataset([\"uniform8ptdata100.csv\", \"vonmises8ptdata100.csv\"])\n",
    "testdata = CircularDataset([\"uniform8ptdata100test.csv\", \"vonmises8ptdata100test.csv\"])\n",
    "iterator = torch.utils.data.DataLoader(dataset, batch_size = batchsize, shuffle = True)\n",
    "testiterator = torch.utils.data.DataLoader(testdata, batch_size = batchsize, shuffle = True)\n",
    "net = CircleNet(8,0,2)\n",
    "optimizer = optim.Adam(net.parameters(),lr = rate)\n",
    "running_loss = 0\n",
    "epochs = 10\n",
    "net.apply(init_weights)\n",
    "net.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for e in range(epochs): \n",
    "    print(running_loss)\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "    i = 0\n",
    "    for dist, labels in iterator: \n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = net(dist.float()/20)\n",
    "        \n",
    "        loss = loss_func(out,torch.max(labels, 1)[1])\n",
    "       \n",
    "           \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "    for dist, labels in testiterator: \n",
    "        ps = net(dist.float()/20)\n",
    "        \n",
    "        i += 1\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "       \n",
    "        top_p2, top_class2 = labels.topk(1, dim = 1)\n",
    "        \n",
    "        equals = top_class == top_class2\n",
    "        \n",
    "        accuracy += torch.sum(equals.float())\n",
    "        \n",
    "    accuracy = accuracy/i/batchsize\n",
    "    print(accuracy)\n",
    "    accuracy = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(vec, num_rotations): \n",
    "    vec2 = np.zeros(len(vec))\n",
    "    for i in range(len(vec)): \n",
    "        vec2[(i + num_rotations )% len(vec)] = vec[i]\n",
    "    return vec2\n",
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1\n",
    "    vm_dist = vonmises.rvs(kappa, size=SAMPLE_SIZE)\n",
    "    vm_dist = (vm_dist + np.pi)/(2*np.pi)*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    \n",
    "    rotate_amt = randint(0,res - 1)\n",
    "    data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptdata100test.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist2 = []\n",
    "for parameter in savednet2.parameters(): \n",
    "    paramlist2 += [parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "savednet2 = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.4111776 ,  1.8812704 , -1.0365207 , -1.0205503 , -0.12043339,\n",
       "        -1.0698339 , -0.76035386,  1.8526413 ],\n",
       "       [-1.8916395 , -2.3316643 , -1.0254574 ,  3.708905  ,  6.4014244 ,\n",
       "         3.3557894 , -1.0132087 , -2.5337431 ]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 = paramlist2[0].detach().numpy()\n",
    "array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.51717466+0.j        ,  1.08125127-0.02763428j,\n",
       "         0.76095235-0.00258182j,  0.05165149+0.04140743j,\n",
       "         0.10629275+0.j        ,  0.05165149-0.04140743j,\n",
       "         0.76095235+0.00258182j,  1.08125127+0.02763428j],\n",
       "       [ 0.58380072+0.j        , -2.09111498+0.04754163j,\n",
       "         0.81855638-0.01887959j,  0.01784901+0.05060379j,\n",
       "         0.03397898+0.j        ,  0.01784901-0.05060379j,\n",
       "         0.81855638+0.01887959j, -2.09111498-0.04754163j]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(array2,fft.ifft(np.identity(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.+0.j        ,  -1.+5.82842712j,  -8.-6.j        ,\n",
       "        -1.-0.17157288j,   8.+0.j        ])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft.rfft(dataset.__getitem__(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CircularDataset([\"vonmises4.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
