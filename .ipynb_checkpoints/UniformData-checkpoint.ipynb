{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.optim as optim\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from scipy.stats import vonmises\n",
    "import numpy.fft as fft \n",
    "res = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define the network to train on the data \n",
    "class CircleNet(nn.Sequential): \n",
    "    def __init__(self, res, dropout, n_out): \n",
    "        super(CircleNet, self).__init__()\n",
    "        self.n_in = res\n",
    "        self.affine1 = nn.Linear(self.n_in, 4)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        ##self.affine2 = nn.Linear(self.n_in//2, self.n_in//2)\n",
    "        ##self.drop2 = nn.Dropout(dropout)\n",
    "        self.affine3 = nn.Linear(4, n_out)\n",
    "    def forward(self, x): \n",
    "        x = F.relu(self.affine1(x))\n",
    "        x = self.drop1(x)\n",
    "        ##x = F.relu(self.affine2(x))\n",
    "        ##x = self.drop2(x)\n",
    "        x = F.relu(self.affine3(x))\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Data Generation Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make some uniform circular data\n",
    "res = 8\n",
    "num_points = 100\n",
    "num_samples = 100\n",
    "data = np.zeros([num_points,res + 1])\n",
    "for i in range(num_points): \n",
    "    for j in range(num_samples): \n",
    "        num = randint(0,res-1)\n",
    "        data[i][num]+= 1\n",
    "        data[i][res] = -1\n",
    "np.savetxt(\"uniform8ptdata100test.csv\", data, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1\n",
    "    vm_dist = vonmises.rvs(kappa, size=SAMPLE_SIZE)\n",
    "    vm_dist = (vm_dist + np.pi)/(2*np.pi)*(res*10)//10\n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    rotate_amt = randint(0,res - 1)\n",
    "    data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptdata100test.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is a class that allows us to load data from csv files and make them into datasets that the dataloader can use\n",
    "class CircularDataset(Dataset): \n",
    "    def __init__(self, data_root): \n",
    "        self.data = []\n",
    "        self.dist_coder = LabelEncoder()\n",
    "        self.dist_list = []\n",
    "        for path in data_root: \n",
    "            array = pd.read_csv(path)\n",
    "            \n",
    "            self.dist_list += [array.values[0,-1]] ##get the distribution type for each file and add it to the list\n",
    "            if len(self.data) == 0: \n",
    "                self.data = array.values\n",
    "            else:\n",
    "                print(self.data.shape)\n",
    "                print(array.values.shape)\n",
    "                self.data = np.concatenate((self.data,array.values), axis = 0)\n",
    "        self.dist_coder.fit(self.dist_list)\n",
    "    def __getitem__(self,idx): \n",
    "        return self.data[idx][0:-1], self.to_one_hot(self.dist_coder,([self.data[idx,-1]]))[0]\n",
    "    def __len__(self): \n",
    "        return len(self.data)\n",
    "    def to_one_hot(self, codec, values):\n",
    "        value_idxs = codec.transform(values)\n",
    "        return torch.eye(len(codec.classes_))[value_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code where we train the network on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 9)\n",
      "(9999, 9)\n",
      "(99, 9)\n",
      "(99, 9)\n",
      "0\n",
      "tensor(0.6700)\n",
      "tensor(1243.7050, grad_fn=<AddBackward0>)\n",
      "tensor(0.6550)\n",
      "tensor(1182.3488, grad_fn=<AddBackward0>)\n",
      "tensor(0.6650)\n",
      "tensor(1179.5945, grad_fn=<AddBackward0>)\n",
      "tensor(0.6550)\n",
      "tensor(1179.1890, grad_fn=<AddBackward0>)\n",
      "tensor(0.6550)\n",
      "tensor(1178.6710, grad_fn=<AddBackward0>)\n",
      "tensor(0.6650)\n",
      "tensor(1178.7299, grad_fn=<AddBackward0>)\n",
      "tensor(0.6550)\n",
      "tensor(1178.8418, grad_fn=<AddBackward0>)\n",
      "tensor(0.6700)\n",
      "tensor(1178.2568, grad_fn=<AddBackward0>)\n",
      "tensor(0.6700)\n",
      "tensor(1178.2000, grad_fn=<AddBackward0>)\n",
      "tensor(0.6550)\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.05)\n",
    "rate = .005\n",
    "batchsize = 10\n",
    "dataset = CircularDataset([\"uniform8ptdata100.csv\", \"vonmises8ptdata100.csv\"])\n",
    "testdata = CircularDataset([\"uniform8ptdata100test.csv\", \"vonmises8ptdata100test.csv\"])\n",
    "iterator = torch.utils.data.DataLoader(dataset, batch_size = batchsize, shuffle = True)\n",
    "testiterator = torch.utils.data.DataLoader(testdata, batch_size = batchsize, shuffle = True)\n",
    "net = CircleNet(8,0,2)\n",
    "optimizer = optim.Adam(net.parameters(),lr = rate)\n",
    "running_loss = 0\n",
    "epochs = 10\n",
    "net.apply(init_weights)\n",
    "net.train()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for e in range(epochs): \n",
    "    print(running_loss)\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "    i = 0\n",
    "    for dist, labels in iterator: \n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = net(dist.float()/20)\n",
    "        \n",
    "        loss = loss_func(out,torch.max(labels, 1)[1])\n",
    "       \n",
    "           \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "    for dist, labels in testiterator: \n",
    "        ps = net(dist.float()/20)\n",
    "        \n",
    "        i += 1\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "       \n",
    "        top_p2, top_class2 = labels.topk(1, dim = 1)\n",
    "        \n",
    "        equals = top_class == top_class2\n",
    "        \n",
    "        accuracy += torch.sum(equals.float())\n",
    "        \n",
    "    accuracy = accuracy/i/batchsize\n",
    "    print(accuracy)\n",
    "    accuracy = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(vec, num_rotations): \n",
    "    vec2 = np.zeros(len(vec))\n",
    "    for i in range(len(vec)): \n",
    "        vec2[(i + num_rotations )% len(vec)] = vec[i]\n",
    "    return vec2\n",
    "data = np.zeros([100,res+1])\n",
    "for i in range(100):\n",
    "    SAMPLE_SIZE = 100\n",
    "    kappa = 1\n",
    "    vm_dist = vonmises.rvs(kappa, size=SAMPLE_SIZE)\n",
    "    vm_dist = (vm_dist + np.pi)/(2*np.pi)*(res*10)//10\n",
    "    \n",
    "    for k in range(SAMPLE_SIZE):\n",
    "        data[i][int(vm_dist[k])] += 1\n",
    "    \n",
    "    rotate_amt = randint(0,res - 1)\n",
    "    data[i,0:-1] = rotate(data[i,0:-1], rotate_amt)\n",
    "    data[i,-1] = -3\n",
    "np.savetxt(\"vonmises8ptdata100test.csv\", data, delimiter = \",\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist2 = []\n",
    "for parameter in net.parameters(): \n",
    "    paramlist2 += [parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "savednet2 = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8267326 ,  1.6260242 ,  1.031658  ,  0.11489279, -1.1927779 ,\n",
       "        -2.3555994 , -1.1457175 ,  1.0627302 ],\n",
       "       [-2.6578832 , -1.647659  ,  0.07332024,  1.0505815 ,  1.7144126 ,\n",
       "         2.1448517 ,  1.0407058 , -1.285145  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 = paramlist2[0].detach().numpy()\n",
    "array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12099289+0.j        ,  0.81314573+0.5403233j ,\n",
       "         0.09350178-0.23839977j, -0.0582681 -0.00402059j,\n",
       "         0.00898094+0.j        , -0.0582681 +0.00402059j,\n",
       "         0.09350178+0.23839977j,  0.81314573-0.5403233j ],\n",
       "       [ 0.05414807+0.j        , -1.08820172-0.24968594j,\n",
       "        -0.25718708+0.09146954j, -0.00487221-0.00783955j,\n",
       "        -0.01150921+0.j        , -0.00487221+0.00783955j,\n",
       "        -0.25718708-0.09146954j, -1.08820172+0.24968594j]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(array2,fft.ifft(np.identity(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft.rfft(dataset.__getitem__(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 1.8267,  1.6260,  1.0317,  0.1149, -1.1928, -2.3556, -1.1457,  1.0627],\n",
       "         [-2.6579, -1.6477,  0.0733,  1.0506,  1.7144,  2.1449,  1.0407, -1.2851]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([0.2029, 0.3341], requires_grad=True), Parameter containing:\n",
       " tensor([[ 4.2196,  3.8495],\n",
       "         [-2.9708, -2.5775]], requires_grad=True), Parameter containing:\n",
       " tensor([-6.3560, 11.3028], requires_grad=True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramlist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b8f394649ed8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0cfe5bf7a0b6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m##x = self.drop2(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "net(torch.from_numpy(dataset.__getitem__(1)[0]).float()/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
